{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìç Location & Census Data Acquisition\n",
    "\n",
    "##  Overview\n",
    "This notebook was designed for **local execution** to acquire **store location and census data** for the project. Unlike the **product API pipeline**, which is designed for periodic updates, this dataset was considered **static** since:\n",
    "- Census data is from **2023 and was not intended to be updated**.\n",
    "- Store locations were **retrieved once**, with no active tracking of new store openings or closures.\n",
    "\n",
    "##  Purpose\n",
    "- Extract and clean **store location data** from Kroger‚Äôs API.\n",
    "- Acquire **U.S. Census data** on **income, poverty, SNAP participation, education, and racial demographics**.\n",
    "- Format and store these datasets for integration into the **main analysis pipeline**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T19:03:07.219141Z",
     "iopub.status.busy": "2022-04-09T19:03:07.218847Z",
     "iopub.status.idle": "2022-04-09T19:03:07.223734Z",
     "shell.execute_reply": "2022-04-09T19:03:07.222724Z",
     "shell.execute_reply.started": "2022-04-09T19:03:07.21911Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import base64\n",
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv, set_key, get_key\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Census Data Acquisition\n",
    "\n",
    "This section extracts **demographic and economic indicators** from the **U.S. Census Bureau‚Äôs ACS 2023 data**.  \n",
    "Key metrics include:\n",
    "- **Population Counts**\n",
    "- **Poverty Rate**\n",
    "- **SNAP Participation**\n",
    "- **Education Levels**\n",
    "- **Racial Demographics**\n",
    "\n",
    "### Why This Data Was Considered Static\n",
    "- Data was pulled **once for 2023** with **no intention to update**.\n",
    "- Unlike product pricing, **demographic shifts occur gradually**, making static data sufficient for this project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cleaned Census Data Saved as 'cleaned_census_data.csv'\n",
      "  ZIP Code  Total Population  Poverty Count  Median Household Income  \\\n",
      "0    00601             16721          10199                  18571.0   \n",
      "1    00602             37510          17504                  21702.0   \n",
      "2    00603             48317          22683                  19243.0   \n",
      "3    00606              5435           2984                  20226.0   \n",
      "4    00610             25413          11145                  23732.0   \n",
      "\n",
      "   SNAP Households  White Population  Black Population  \\\n",
      "0             3219             13904               314   \n",
      "1             7138             13781               520   \n",
      "2            10261             35550              1572   \n",
      "3             1056              3697                12   \n",
      "4             4936              6582               525   \n",
      "\n",
      "   American Indian Population  Asian Population  Pacific Islander Population  \\\n",
      "0                           7                19                            0   \n",
      "1                          73                44                            0   \n",
      "2                          32                 8                            0   \n",
      "3                           0                15                            0   \n",
      "4                           1                 0                            0   \n",
      "\n",
      "   Other Race Population  Two or More Races Population  High School Graduate  \\\n",
      "0                   1120                          1357                  3356   \n",
      "1                   1732                         21360                  6328   \n",
      "2                   6231                          4924                 10799   \n",
      "3                   1332                           379                  1304   \n",
      "4                   2437                         15868                  4899   \n",
      "\n",
      "   Bachelor's Degree  Master's Degree  Doctorate Degree  \n",
      "0               1678              408                15  \n",
      "1               5275             1297               116  \n",
      "2               5980             2332               427  \n",
      "3                271              182                 0  \n",
      "4               3402              877                29  \n",
      "<bound method NDFrame.describe of       ZIP Code  Total Population  Poverty Count  Median Household Income  \\\n",
      "0        00601             16721          10199                  18571.0   \n",
      "1        00602             37510          17504                  21702.0   \n",
      "2        00603             48317          22683                  19243.0   \n",
      "3        00606              5435           2984                  20226.0   \n",
      "4        00610             25413          11145                  23732.0   \n",
      "...        ...               ...            ...                      ...   \n",
      "33767    99923                25              0                      NaN   \n",
      "33768    99925               854            144                  60000.0   \n",
      "33769    99926              1385            212                  69464.0   \n",
      "33770    99927                18              0                      NaN   \n",
      "33771    99929              2105            226                  64659.0   \n",
      "\n",
      "       SNAP Households  White Population  Black Population  \\\n",
      "0                 3219             13904               314   \n",
      "1                 7138             13781               520   \n",
      "2                10261             35550              1572   \n",
      "3                 1056              3697                12   \n",
      "4                 4936              6582               525   \n",
      "...                ...               ...               ...   \n",
      "33767                0                17                 0   \n",
      "33768               42               356                 4   \n",
      "33769              110                79                 4   \n",
      "33770                0                18                 0   \n",
      "33771              105              1160                 2   \n",
      "\n",
      "       American Indian Population  Asian Population  \\\n",
      "0                               7                19   \n",
      "1                              73                44   \n",
      "2                              32                 8   \n",
      "3                               0                15   \n",
      "4                               1                 0   \n",
      "...                           ...               ...   \n",
      "33767                           8                 0   \n",
      "33768                         294                 8   \n",
      "33769                        1113                13   \n",
      "33770                           0                 0   \n",
      "33771                         438                91   \n",
      "\n",
      "       Pacific Islander Population  Other Race Population  \\\n",
      "0                                0                   1120   \n",
      "1                                0                   1732   \n",
      "2                                0                   6231   \n",
      "3                                0                   1332   \n",
      "4                                0                   2437   \n",
      "...                            ...                    ...   \n",
      "33767                            0                      0   \n",
      "33768                            2                      4   \n",
      "33769                           18                      0   \n",
      "33770                            0                      0   \n",
      "33771                           26                      3   \n",
      "\n",
      "       Two or More Races Population  High School Graduate  Bachelor's Degree  \\\n",
      "0                              1357                  3356               1678   \n",
      "1                             21360                  6328               5275   \n",
      "2                              4924                 10799               5980   \n",
      "3                               379                  1304                271   \n",
      "4                             15868                  4899               3402   \n",
      "...                             ...                   ...                ...   \n",
      "33767                             0                     8                  0   \n",
      "33768                           186                   191                 74   \n",
      "33769                           158                   270                 33   \n",
      "33770                             0                    18                  0   \n",
      "33771                           385                   420                218   \n",
      "\n",
      "       Master's Degree  Doctorate Degree  \n",
      "0                  408                15  \n",
      "1                 1297               116  \n",
      "2                 2332               427  \n",
      "3                  182                 0  \n",
      "4                  877                29  \n",
      "...                ...               ...  \n",
      "33767                0                 0  \n",
      "33768               27                 0  \n",
      "33769               37                 5  \n",
      "33770                0                 0  \n",
      "33771               54                 6  \n",
      "\n",
      "[33772 rows x 16 columns]>\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = os.path.abspath(os.path.dirname(os.getcwd()))\n",
    "\n",
    "# Define directories relative to `BASE_DIR`\n",
    "SRC_DIR = os.path.join(BASE_DIR, \"src\")  # Points to `src/`\n",
    "DATA_DIR = os.path.join(SRC_DIR, \"data/Census_Files\")  # Points to `src/data/Census_Files`\n",
    "\n",
    "# Ensure paths are correctly set\n",
    "census_files = {\n",
    "    \"Population\": os.path.join(DATA_DIR, \"ACSDT5Y2023.B01003\", \"ACSDT5Y2023.B01003-Data.csv\"),\n",
    "    \"Poverty Rate\": os.path.join(DATA_DIR, \"ACSDT5Y2023.B17001\", \"ACSDT5Y2023.B17001-Data.csv\"),\n",
    "    \"Median Income\": os.path.join(DATA_DIR, \"ACSDT5Y2023.B19013\", \"ACSDT5Y2023.B19013-Data.csv\"),\n",
    "    \"SNAP Participation\": os.path.join(DATA_DIR, \"ACSDT5Y2023.B22010\", \"ACSDT5Y2023.B22010-Data.csv\"),\n",
    "    \"Race Demographics\": os.path.join(DATA_DIR, \"ACSDT5Y2023.B02001\", \"ACSDT5Y2023.B02001-Data.csv\"),\n",
    "    \"Educational Attainment\": os.path.join(DATA_DIR, \"ACSDT5Y2023.B15003\", \"ACSDT5Y2023.B15003-Data.csv\")\n",
    "}\n",
    "\n",
    "# Function to clean and standardize Census data\n",
    "def clean_census_data(df, value_column, new_column_name, zip_column=\"NAME\"):\n",
    "    \"\"\"Cleans Census data by removing headers, extracting ZIP codes, and selecting relevant columns.\"\"\"\n",
    "    df = df.iloc[1:].reset_index(drop=True)\n",
    "    df[\"ZIP Code\"] = df[zip_column].str.extract(r'(\\d{5})')\n",
    "    df[new_column_name] = pd.to_numeric(df[value_column], errors=\"coerce\")\n",
    "    return df[[\"ZIP Code\", new_column_name]]\n",
    "\n",
    "# Load and clean each dataset\n",
    "cleaned_data = {\n",
    "    \"Population\": clean_census_data(pd.read_csv(census_files[\"Population\"], low_memory=False), \"B01003_001E\", \"Total Population\"),\n",
    "    \"Poverty Rate\": clean_census_data(pd.read_csv(census_files[\"Poverty Rate\"], low_memory=False), \"B17001_002E\", \"Poverty Count\"),\n",
    "    \"Median Income\": clean_census_data(pd.read_csv(census_files[\"Median Income\"], low_memory=False), \"B19013_001E\", \"Median Household Income\"),\n",
    "    \"SNAP Participation\": clean_census_data(pd.read_csv(census_files[\"SNAP Participation\"], low_memory=False), \"B22010_002E\", \"SNAP Households\"),\n",
    "    \"White Population\": clean_census_data(pd.read_csv(census_files[\"Race Demographics\"], low_memory=False), \"B02001_002E\", \"White Population\"),\n",
    "    \"Black Population\": clean_census_data(pd.read_csv(census_files[\"Race Demographics\"], low_memory=False), \"B02001_003E\", \"Black Population\"),\n",
    "    \"American Indian Population\": clean_census_data(pd.read_csv(census_files[\"Race Demographics\"], low_memory=False), \"B02001_004E\", \"American Indian Population\"),\n",
    "    \"Asian Population\": clean_census_data(pd.read_csv(census_files[\"Race Demographics\"], low_memory=False), \"B02001_005E\", \"Asian Population\"),\n",
    "    \"Pacific Islander Population\": clean_census_data(pd.read_csv(census_files[\"Race Demographics\"], low_memory=False), \"B02001_006E\", \"Pacific Islander Population\"),\n",
    "    \"Other Race Population\": clean_census_data(pd.read_csv(census_files[\"Race Demographics\"], low_memory=False), \"B02001_007E\", \"Other Race Population\"),\n",
    "    \"Two or More Races Population\": clean_census_data(pd.read_csv(census_files[\"Race Demographics\"], low_memory=False), \"B02001_008E\", \"Two or More Races Population\"),\n",
    "    \"High School Graduate\": clean_census_data(pd.read_csv(census_files[\"Educational Attainment\"], low_memory=False), \"B15003_017E\", \"High School Graduate\"),\n",
    "    \"Bachelor's Degree\": clean_census_data(pd.read_csv(census_files[\"Educational Attainment\"], low_memory=False), \"B15003_022E\", \"Bachelor's Degree\"),\n",
    "    \"Master's Degree\": clean_census_data(pd.read_csv(census_files[\"Educational Attainment\"], low_memory=False), \"B15003_023E\", \"Master's Degree\"),\n",
    "    \"Doctorate Degree\": clean_census_data(pd.read_csv(census_files[\"Educational Attainment\"], low_memory=False), \"B15003_025E\", \"Doctorate Degree\")\n",
    "}\n",
    "\n",
    "# Merge datasets on ZIP Code\n",
    "census_merged = cleaned_data[\"Population\"]\n",
    "for key, df in cleaned_data.items():\n",
    "    if key != \"Population\":\n",
    "        census_merged = census_merged.merge(df, on=\"ZIP Code\", how=\"left\")\n",
    "\n",
    "# Save cleaned and merged Census data\n",
    "output_file = os.path.join(DATA_DIR, \"cleaned_census_data.csv\")\n",
    "census_merged.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"Cleaned Census Data Saved as 'cleaned_census_data.csv'\")\n",
    "print(census_merged.head())\n",
    "print(census_merged.describe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Access & Credentials\n",
    "\n",
    "This notebook retrieves **store location data** from Kroger‚Äôs API, which requires authentication via **client credentials** stored in an `.env` file.  \n",
    "Since this notebook was designed for **local execution**, sensitive credentials are not embedded in the script.\n",
    "\n",
    "### Key Considerations:\n",
    "- The API credentials are stored in a **local environment file (`.env`)**.\n",
    "- The authentication process follows **OAuth2**, retrieving an **access token** before making requests.\n",
    "- This notebook **was not refactored** into a modular pipeline since the store dataset was intended to remain static."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-09T19:03:15.252183Z",
     "iopub.status.busy": "2022-04-09T19:03:15.251894Z",
     "iopub.status.idle": "2022-04-09T19:03:15.421975Z",
     "shell.execute_reply": "2022-04-09T19:03:15.421113Z",
     "shell.execute_reply.started": "2022-04-09T19:03:15.252152Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZHNjaXByb2plY3QtMjQzMjYxMjQzMDM0MjQ1NTYzNWE2ZTZlNzk2ODZmNWE1NzQ3NDc1NjY1NjkzOTMzNTU2NDRhNTc0ZjRhMmYzODQ4Nzk0MzZiMzMzOTZmNzYyZjRiNzQ3Mzc0NTg2NjZkNGMzMDYxNmE3YTMzNTQ2MjYxNDM1NjRiMjM3NDA0MDM5MTI0Nzg4MDY0NzptVlpscnpGTVhSSGFTeVZjY1loSlRDUUZ1bmhQcldyQ1Q1V3g1cGND\n",
      "‚úÖ Access Token Retrieved and Stored!\n",
      "üîπ Token: eyJhbGciOiJSUzI1NiIs...\n",
      "üîπ Token Expiration Time: 2025-03-04 17:48:19.488080\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "ENV_FILE = \"kroger_client_info.env\"  # Define .env file path\n",
    "\n",
    "load_dotenv()\n",
    "CLIENT_ID = get_key(ENV_FILE, \"KROGER_CLIENT_ID\")\n",
    "CLIENT_SECRET = get_key(ENV_FILE, \"KROGER_CLIENT_SECRET\")\n",
    "\n",
    "# Encode CLIENT_ID and CLIENT_SECRET in Base64\n",
    "encoded_auth = base64.b64encode(f\"{CLIENT_ID}:{CLIENT_SECRET}\".encode()).decode()\n",
    "\n",
    "print(encoded_auth)\n",
    "\n",
    "# Define API endpoint and headers\n",
    "TOKEN_URL = \"https://api-ce.kroger.com/v1/connect/oauth2/token\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Basic {encoded_auth}\",\n",
    "    \"Content-Type\": \"application/x-www-form-urlencoded\"\n",
    "}\n",
    "\n",
    "# Define request body\n",
    "data = \"grant_type=client_credentials&scope=product.compact\"  # Modify scope as needed\n",
    "\n",
    "# Make POST request to get access token\n",
    "response = requests.post(TOKEN_URL, headers=headers, data=data)\n",
    "\n",
    "# Handle response\n",
    "if response.status_code == 200:\n",
    "    response_data = response.json()\n",
    "    access_token = response_data.get(\"access_token\")\n",
    "    expires_in = response_data.get(\"expires_in\", 1800)  # Default to 1800 seconds if missing\n",
    "\n",
    "    # Store token and expiration timestamp\n",
    "    token_expiration_time = datetime.now() + timedelta(seconds=expires_in)\n",
    "    os.environ[\"PRODUCT_COMPACT_ACCESS_TOKEN\"] = access_token\n",
    "    os.environ[\"PRODUCT_COMPACT_ACCESS_TOKEN_EXPIRATION\"] = str(token_expiration_time)\n",
    "    \n",
    "    # Save token details to .env file for persistent storage\n",
    "    set_key(ENV_FILE, \"PRODUCT_COMPACT_ACCESS_TOKEN\", access_token)\n",
    "    set_key(ENV_FILE, \"PRODUCT_COMPACT_ACCESS_TOKEN_EXPIRATION\", token_expiration_time.isoformat())\n",
    "\n",
    "    print(\"Access Token Retrieved and Stored!\")\n",
    "    print(f\"üîπ Token: {access_token[:20]}...\")  # Only print part of the token for security\n",
    "    print(f\"üîπ Token Expiration Time: {token_expiration_time}\")\n",
    "\n",
    "else:\n",
    "    print(\"Failed to retrieve access token\")\n",
    "    print(\"üîπ Status Code:\", response.status_code)\n",
    "    print(\"üîπ Response:\", response.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kroger Location API Integration\n",
    "\n",
    "### Overview\n",
    "This module retrieves **store location data** from Kroger‚Äôs API using **OAuth2 authentication**. It allows searching for **grocery store locations near a given ZIP code**, providing details such as **store name, address, and distance** from the search point.\n",
    "\n",
    "### Key Functions\n",
    "#### `get_kroger_location_token()`\n",
    "- Manages **OAuth2 token retrieval and refresh** for accessing the Kroger Location API.\n",
    "- Requests a **new token** if the current one has expired.\n",
    "- Stores tokens **securely in an environment file (`.env`)**.\n",
    "\n",
    "#### `search_kroger_locations(zip_code, radius, limit)`\n",
    "- Searches for **Kroger stores within a given ZIP code**.\n",
    "- Allows customization of the **search radius (default: 20 miles)** and **number of results**.\n",
    "- Handles **API errors gracefully**, ensuring reliable data retrieval.\n",
    "\n",
    "### Purpose\n",
    "This function was used for **one-time store location extraction** but could be **adapted for periodic updates** to track **new store openings and closures**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_URL = \"https://api-ce.kroger.com/v1/connect/oauth2/token\"\n",
    "\n",
    "def get_kroger_location_token():\n",
    "    \"\"\"Retrieve or refresh the Kroger Location API access token.\"\"\"\n",
    "    token = os.getenv(\"LOCATION_ACCESS_TOKEN\")\n",
    "    expiration = os.getenv(\"LOCATION_TOKEN_EXPIRATION\")\n",
    "\n",
    "    # If there's no token or it has expired, request a new one\n",
    "    if not token or datetime.now() >= datetime.fromisoformat(expiration):\n",
    "        print(\"Location Token expired or missing, requesting a new one...\")\n",
    "\n",
    "        encoded_auth = base64.b64encode(f\"{CLIENT_ID}:{CLIENT_SECRET}\".encode()).decode()\n",
    "\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Basic {encoded_auth}\",\n",
    "            \"Content-Type\": \"application/x-www-form-urlencoded\"\n",
    "        }\n",
    "\n",
    "        data = \"grant_type=client_credentials\"\n",
    "\n",
    "        response = requests.post(TOKEN_URL, headers=headers, data=data)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            response_data = response.json()\n",
    "            token = response_data.get(\"access_token\")\n",
    "            expires_in = response_data.get(\"expires_in\", 1800)\n",
    "            expiration_time = datetime.now() + timedelta(seconds=expires_in)\n",
    "\n",
    "            # Store new token\n",
    "            os.environ[\"LOCATION_ACCESS_TOKEN\"] = token\n",
    "            os.environ[\"LOCATION_TOKEN_EXPIRATION\"] = str(expiration_time)\n",
    "            \n",
    "            # Save token details to .env file for persistent storage\n",
    "            set_key(ENV_FILE, \"LOCATION_ACCESS_TOKEN\", token)\n",
    "            set_key(ENV_FILE, \"LOCATION_ACCESS_TOKEN_EXPIRATION\", expiration_time.isoformat())\n",
    "\n",
    "            print(\"New Location Token Retrieved!\")\n",
    "        else:\n",
    "            print(\"Failed to retrieve location token:\", response.json())\n",
    "\n",
    "    return token\n",
    "\n",
    "def search_kroger_locations(zip_code, radius = 20, limit=5):\n",
    "    \"\"\"Search for Kroger store locations near a given ZIP code.\"\"\"\n",
    "    token = get_kroger_location_token()  # Get a valid token\n",
    "\n",
    "    # Define API URL for locations\n",
    "    LOCATIONS_API_URL = \"https://api-ce.kroger.com/v1/locations\"\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {token}\",\n",
    "        \"Accept\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    params = {\n",
    "        \"filter.zipCode.near\": zip_code,  # Search by ZIP code\n",
    "        \"filter.radiusInMiles\": radius, # Set search radius\n",
    "        \"filter.limit\": limit  # Limit number of results\n",
    "    }\n",
    "\n",
    "\n",
    "    try:\n",
    "        response = requests.get(LOCATIONS_API_URL, headers=headers, params=params)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching locations for ZIP {zip_code}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZIP Code-Based Store Location Retrieval\n",
    "\n",
    "### Overview\n",
    "This section queries **Kroger‚Äôs Location API** to retrieve **store locations by ZIP code**, dynamically adjusting search parameters based on **population density**.\n",
    "\n",
    "### Key Features\n",
    "- **Dynamic Search Radius**  \n",
    "  - Urban areas (**high population density**) ‚Üí **smaller radius** (e.g., 15 miles).  \n",
    "  - Rural areas (**low population density**) ‚Üí **larger radius** (e.g., 100 miles).  \n",
    "\n",
    "- **ZIP Code Processing Logic**  \n",
    "  - Uses a **pre-filtered list** of ZIP codes from Census data.  \n",
    "  - **Tracks processed ZIPs** in a file (`processed_zips.txt`) to prevent redundant queries.  \n",
    "  - **Reduces API requests** by querying every **third ZIP code** (`zip_codes[::3]`).  \n",
    "\n",
    "- **Data Storage & Deduplication**  \n",
    "  - Prevents **duplicate store records** using a set of **existing Location IDs**.  \n",
    "  - **Appends new data** to `kroger_locations.csv` only when new stores are found.  \n",
    "  - Displays a **real-time progress tracker** to monitor request completion.\n",
    "\n",
    "### Purpose\n",
    "This method provides **targeted store location retrieval** while **minimizing API calls** and avoiding redundant queries.  \n",
    "Although designed for **one-time execution**, it could be adapted for **periodic updates** to track **store openings and closures**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Location Token expired or missing, requesting a new one...\n",
      "‚úÖ New Location Token Retrieved!\n",
      "üîÑ Progress: 132/132 ZIP codes processed\n",
      "‚úÖ Test Kroger store locations saved as 'kroger_locations.csv'.\n",
      "  Location ID                                    Store Name Store Number  \\\n",
      "0    542FC805          Harris Teeter - - Philadelphia Spoke        FC805   \n",
      "1    09700336                     Harris Teeter - Long Neck        00336   \n",
      "2    09700327                       Harris Teeter - Bayside        00327   \n",
      "3    09700380            Harris Teeter - Easton Marketplace        00380   \n",
      "4    09700392  Harris Teeter - The Shops at Canton Crossing        00392   \n",
      "\n",
      "  Chain Name  Division Number               Address          City State  \\\n",
      "0       HART              542    7750 Essington Ave  Philadelphia    PA   \n",
      "1       HART               97     26370 Bay Farm Rd     Millsboro    DE   \n",
      "2       HART               97  31221 Americana Pkwy    Selbyville    DE   \n",
      "3       HART               97    28528 Marlboro Ave        Easton    MD   \n",
      "4       HART               97        3779 Boston St     Baltimore    MD   \n",
      "\n",
      "  ZIP Code  \n",
      "0    07064  \n",
      "1    08004  \n",
      "2    08004  \n",
      "3    08004  \n",
      "4    08004  \n"
     ]
    }
   ],
   "source": [
    "# Load census data, create a dictionary with ZIP and Pop, create a list of ZIP Codes\n",
    "census_df = pd.read_csv(\"cleaned_census_data.csv\", dtype={\"ZIP Code\": str})\n",
    "zip_pop_map = dict(zip(census_df[\"ZIP Code\"],census_df[\"Total Population\"].fillna(0)))\n",
    "zip_codes  = list(zip_pop_map.keys())\n",
    "\n",
    "# Function to set dynamic search radius\n",
    "def get_dynamic_radius(population):\n",
    "    \"\"\"Set search radius dynamically based on population density.\"\"\"\n",
    "    if population > 100000:\n",
    "        return 15  # Dense urban areas\n",
    "    elif population > 50000:\n",
    "        return 25  # Urban areas\n",
    "    elif population > 20000:\n",
    "        return 50  # Suburban areas\n",
    "    else:\n",
    "        return 100  # Rural areas\n",
    "\n",
    "# Load processed ZIPs from a file\n",
    "processed_zip_file = \"processed_zips.txt\"\n",
    "\n",
    "# Ensure the file exists\n",
    "if not os.path.exists(processed_zip_file):\n",
    "    open(processed_zip_file, \"w\").close()  # Creates an empty file\n",
    "\n",
    "# Load processed ZIPs from the file\n",
    "with open(processed_zip_file, \"r\") as f:\n",
    "    processed_zip_codes = set(f.read().splitlines())\n",
    "\n",
    "# Generate condensed ZIP list and remove processed ZIPs\n",
    "reduced_zip_list = [zip_code for zip_code in zip_codes[::3] if zip_code not in processed_zip_codes]\n",
    "\n",
    "# Batches each run to a smaller subset\n",
    "condensed_zip_list = reduced_zip_list[:2000]\n",
    "\n",
    "# Initialize storage elements\n",
    "stores = []\n",
    "existing_loc_ids = set()\n",
    "request_count = 0\n",
    "total_requests = len(condensed_zip_list)\n",
    "\n",
    "stores_file = \"kroger_locations.csv\"\n",
    "if os.path.exists(stores_file) and os.path.getsize(stores_file) > 0:\n",
    "    existing_stores_df = pd.read_csv(stores_file, dtype={\"ZIP Code\": str}) \n",
    "    stores.extend(existing_stores_df.to_dict(orient=\"records\"))\n",
    "    existing_loc_ids.update(existing_stores_df[\"Location ID\"].astype(str).tolist()) # prevent duplicate records\n",
    "else:\n",
    "    print(\"No existing stores file found or the file is empty.\")\n",
    "    \n",
    "# Main loop for processing ZIP Code searches\n",
    "for i, zip_code in enumerate(condensed_zip_list, start=1):\n",
    "    if zip_code in processed_zip_codes:\n",
    "        print(f\"Skipping {zip_code}, already processed.\")\n",
    "        continue  # Skip already processed ZIPs\n",
    "    \n",
    "    if len(processed_zip_codes) >= len(zip_codes):\n",
    "        print(\"All ZIP codes processed. Exiting loop.\")\n",
    "        break\n",
    "    \n",
    "    try:\n",
    "        population = zip_pop_map.get(zip_code, 0)\n",
    "        radius = get_dynamic_radius(population)# adjust param based on population density and adding \n",
    "        \n",
    "        location_results = search_kroger_locations(zip_code, radius, limit = 100)\n",
    "        request_count += 1\n",
    "        \n",
    "        if location_results and \"data\"  in location_results:\n",
    "            for store in location_results[\"data\"]:\n",
    "                location_id = store[\"locationId\"]\n",
    "                if location_id not in existing_loc_ids:\n",
    "                    stores.append({\n",
    "                        \"Location ID\": location_id,\n",
    "                        \"Store Name\": store.get(\"name\", \"unknown\"),\n",
    "                        \"Store Number\": store.get(\"storeNumber\", \"unknown\"),\n",
    "                        \"Chain Name\": store.get(\"chain\", \"unknown\"),\n",
    "                        \"Division Number\": store.get(\"divisionNumber\", \"unknown\"),\n",
    "                        \"Address\": store.get(\"address\", {}).get(\"addressLine1\", \"Unknown\"),\n",
    "                        \"City\": store.get(\"address\", {}).get(\"city\", \"Unknown\"),\n",
    "                        \"State\": store.get(\"address\", {}).get(\"state\", \"Unknown\"),\n",
    "                        \"ZIP Code\": zip_code})\n",
    "                    existing_loc_ids.add(location_id)\n",
    "        \n",
    "        processed_zip_codes.add(zip_code)\n",
    "        with open(processed_zip_file, \"a\") as f:\n",
    "            f.write(zip_code + \"\\n\")\n",
    "        \n",
    "        # Mental sanity feature so I don't constantly wonder how many records have been  processed    \n",
    "        sys.stdout.write(f\"\\rProgress: {i}/{total_requests} ZIP codes processed\")\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing ZIP {zip_code}: {e}\")\n",
    "    \n",
    "    time.sleep(1) # prevent rate limiting\n",
    "\n",
    "\n",
    "# Append results to file only if there is new data\n",
    "if stores:\n",
    "    stores_df = pd.DataFrame(stores)\n",
    "    stores_df.to_csv(stores_file, mode=\"a\", index=False, header=not os.path.exists(stores_file))\n",
    "    print(f\"\\nTest Kroger store locations saved as '{stores_file}'.\")\n",
    "else:\n",
    "    print(\"\\nNo new store data found. Skipping file update.\")\n",
    "\n",
    "print(stores_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Thoughts\n",
    "\n",
    "### Summary\n",
    "- **Successfully acquired and cleaned location and census data**.\n",
    "- **Ensured ZIP codes and population data were properly formatted**.\n",
    "- **Stored the dataset for integration with pricing and correlation analysis**.\n",
    "\n",
    "### Next Steps\n",
    "- **Consider automating store location updates on a scheduled basis**.\n",
    "- **If new ACS data is available, an updated census pull could improve analysis**.\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30176,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
